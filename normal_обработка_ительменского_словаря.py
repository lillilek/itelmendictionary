# -*- coding: utf-8 -*-
"""normal_обработка_ительменского_словаря.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13jM0JhywCAOlLIAYq2HnN_dc_dV5D9tX
"""

!pip install PyPDF2

!pip3 install pdfminer.six

import re
import pandas as pd
from pdfminer.high_level import extract_text
file_path = "/content/Володин и др._2021_Полный ительменско-русский словарь (1)-397-488.pdf"
text = extract_text(file_path)

# 1) Удаляем строки с номерами страниц (четные числа от 398 до 488)
#    и строки вида "русско-ительменский индекс 398"
clean_lines = []
for line in text.split("\n"):
    stripped = line.strip()

    # Пропускаем пустые строки
    if not stripped:
        clean_lines.append("")
        continue

    # Если строка точно совпадает с четным номером от 398 до 488
    if re.match(r"^\d+$", stripped):
        num = int(stripped)
        if 398 <= num <= 488 and num % 2 == 0:
            # Пропускаем эту строку (не добавляем)
            continue

    # Если строка содержит "русско-ительменский индекс" и за ним следует номер
    # Например: "русско-ительменский индекс 398"
    if re.search(r"русско-ительменский индекс\s+\d+", stripped, re.IGNORECASE):
        # Пропускаем такую строку
        continue

    # Если строка не подходит под условия удаления, оставляем
    clean_lines.append(stripped)

# Теперь у нас есть "очищенный" текст без номеров страниц и строк с "русско-ительменский индекс XXX"
clean_text = "\n".join(clean_lines)

############################################################
# Дальше используем ваш алгоритм объединения многострочных записей
# и парсинга
############################################################

pos_tags = {
    "сущ", "мест", "п1", "п2", "неп", "нареч", "прил", "межд",
    "собств", "инф", "с.", "союз", "предл", "част", "числ", "А"
}

def strip_semicolon(token: str) -> str:
    return token.rstrip(";")

def is_new_russian_line(line: str) -> bool:
    """
    Определяем, является ли строка началом новой записи (русского слова).
    Правило (можно донастроить):
    - строка не пуста, не начинается с пробела
    - первое слово (без ";") не тег
    - второе слово (без ";") не тег, если есть
    """
    stripped = line.strip()
    if not stripped:
        return False
    if stripped.startswith(" "):
        return False

    words = stripped.split()
    first_word = strip_semicolon(words[0])
    if first_word in pos_tags:
        return False

    if len(words) == 1:
        return True

    second_word = strip_semicolon(words[1])
    if second_word in pos_tags:
        return False

    return True

lines = clean_text.split("\n")

blocks = []
current_block = []

for i, line in enumerate(lines):
    stripped = line.strip()

    # Добавим даже пустые строки в current_block,
    # чтобы возможные переносы перевода не терялись
    if not stripped:
        current_block.append("")
        continue

    if is_new_russian_line(stripped):
        # Начинается новый блок
        if current_block:
            block_text = "\n".join(current_block).strip()
            if block_text:
                blocks.append(block_text)
        current_block = [stripped]
    else:
        # Продолжение предыдущего блока
        current_block.append(stripped)

# Добавляем последний блок
if current_block:
    block_text = "\n".join(current_block).strip()
    if block_text:
        blocks.append(block_text)

########################################################
# Теперь парсим каждый блок
########################################################

data = []

def process_block(block: str):
    """
    1) Разбиваем block на токены (split()).
    2) Ищем индекс i, где token[i+1] (без ";") ∈ pos_tags => граница (русское/ительменское).
    3) Русское слово = tokens[:i]
    4) Ительменское = tokens[i:]
    5) Если в ительменском тексте есть ";", => multiple translations
       иначе берем тег из tokens[i+1].
    """
    tokens = block.split()
    if not tokens:
        return
    boundary = None
    for i in range(len(tokens) - 1):
        nxt = strip_semicolon(tokens[i+1])
        if nxt in pos_tags:
            boundary = i
            break

    if boundary is None:
        return

    russian_part = tokens[:boundary]
    itelmen_part_tokens = tokens[boundary:]
    itelmen_str = " ".join(itelmen_part_tokens)

    if ";" in itelmen_str:
        pos_value = "multiple translations"
    else:
        if len(itelmen_part_tokens) > 1:
            pos_value = strip_semicolon(itelmen_part_tokens[1])
        else:
            pos_value = ""

    if russian_part and itelmen_part_tokens:
        data.append([
            " ".join(russian_part),
            itelmen_str,
            pos_value
        ])

for block in blocks:
    process_block(block)

df = pd.DataFrame(data, columns=["Русское слово", "Ительменское слово", "Часть речи"])

df.to_csv("russian_itelmen_dictionary_gol.csv", index=False)

import re
import pandas as pd

# Набор символов, характерных для ительменского языка
itelmen_chars = r"[ʼӄӈӼӽӃӇʔ˚ӑӘәЉљԒԓŎŏЊњЎў]"

def is_itelmen_word(word: str) -> bool:
    """
    Проверяет, есть ли в слове символы, характерные для ительменского языка.
    """
    return bool(re.search(itelmen_chars, word))

def fix_itelmen_in_russian_skip_first(df: pd.DataFrame) -> pd.DataFrame:
    """
    Проходит по каждой строке DataFrame. В столбце «Русское слово» мы не трогаем
    первый токен, а все остальные токены проверяем:
    - Если они содержат ительменские символы, переносим их в «Ительменское слово».
    """
    new_russian_col = []
    new_itelmen_col = []

    for idx, row in df.iterrows():
        russian_text = row["Русское слово"]
        itelmen_text = row["Ительменское слово"]

        # Разбиваем «русское слово» и «ительменский перевод» на токены
        russian_tokens = russian_text.split()
        itelmen_tokens = itelmen_text.split()

        # Списки для сохранения
        keep_tokens = []
        moved_tokens = []

        if len(russian_tokens) > 0:
            # 1) Всегда оставляем первый токен без проверки
            keep_tokens.append(russian_tokens[0])

            # 2) Начиная со второго токена - проверяем
            for tok in russian_tokens[1:]:
                if is_itelmen_word(tok):
                    moved_tokens.append(tok)
                else:
                    keep_tokens.append(tok)

        # Собираем заново
        new_russian = " ".join(keep_tokens).strip()
        # Добавляем «перемещённые» токены в начало (или в конец) «Ительменского перевода»
        new_itelmen = " ".join(moved_tokens + itelmen_tokens).strip()

        new_russian_col.append(new_russian)
        new_itelmen_col.append(new_itelmen)

    # Обновляем DataFrame
    df["Русское слово"] = new_russian_col
    df["Ительменское слово"] = new_itelmen_col

    return df

# Пример использования:
df = pd.read_csv("russian_itelmen_dictionary_gol.csv")  # Ваш уже полученный датафрейм
df_fixed = fix_itelmen_in_russian_skip_first(df)
df_fixed.to_csv("russian_itelmen_dictionary_fixed.csv", index=False)
print(df_fixed.head(30))

from IPython.display import display
display(df_fixed)